# cracked_bikes

Distributed web crawler optimized for collecting data across 1000+ websites on a daily cadence to provide analytics and keep track of trends by make, stock, location, and other data points. Developed 30+ spiders using Scrapy Splash in Python, targeting bicycle shop websites in Colorado. Cleaned and processed the data through Google Cloud Platform, to generate visualization and reports to get interest from bike manufacturers for potential partnerships and contracts.
